{"cells":[{"cell_type":"markdown","metadata":{"id":"3kyfh_Y2ZyOO"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13WTEZELa06FwkxSxOQjG92yvSjno8HCq?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"6ktCEcrO1tcp"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15841,"status":"ok","timestamp":1646721621602,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"0Pvbjxin1ual","outputId":"65822349-1430-42b8-9ad8-15842919a26c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install sentencepiece\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTWSf1E91xh-"},"outputs":[],"source":["import time\n","import datetime\n","import tensorflow as tf\n","import torch\n","import pandas as pd\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import os\n","from sklearn.metrics import accuracy_score, mean_absolute_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18610,"status":"ok","timestamp":1646721649447,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"R8GndV0u1za7","outputId":"3019fefe-b781-4ebd-a86f-f4c8ef3d7b2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12310,"status":"ok","timestamp":1646721661748,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"mOUkQfqd10It","outputId":"bc93cb15-6f87-4c22-b0e2-91244194158f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}],"source":["# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"Xx977fJe_VjA"},"source":["# Start Predicting (Binary)\n","\n","> IndoLEM Twitter Binary Sentiment Dataset"]},{"cell_type":"markdown","metadata":{"id":"xdTPy3yBMa88"},"source":["## Load the Indonesian sentiment data obtained from IndoLEM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":2476,"status":"ok","timestamp":1646721664219,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"oyvorTTh11y1","outputId":"9c0c4da0-8923-4447-da48-44b34443c056"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-c445d24d-ffaa-496e-a3b9-2238275ea51f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#Sports Perempuan Golkar Makassar Dibekali Ilm...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Se-jauh\"nya, Se-kenal\"nya, Se-pisah\"nya, Se-cu...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sekedar Shared Ucapan Terimakasih Charles Hono...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Wah pak Jokowi sudah mendapat nilai positif di...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penelpon : raffi ahmad oh raffi ahmad..... *bu...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5043</th>\n","      <td>linen nya terasa agak gatal... mungkin kurang ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5044</th>\n","      <td>Didaskaleinophobia adalah takut akan pergi ke ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5045</th>\n","      <td>Iklan partai Demokrat Katakan Tidak Pada Korup...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5046</th>\n","      <td>Tempat tidurnya nyaman toilet kurang bersih</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5047</th>\n","      <td>Cari Anggota Baru, Geng Motor Sebar Formulir k...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5048 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c445d24d-ffaa-496e-a3b9-2238275ea51f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c445d24d-ffaa-496e-a3b9-2238275ea51f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c445d24d-ffaa-496e-a3b9-2238275ea51f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               sentence  sentiment\n","0     #Sports Perempuan Golkar Makassar Dibekali Ilm...          1\n","1     Se-jauh\"nya, Se-kenal\"nya, Se-pisah\"nya, Se-cu...          1\n","2     Sekedar Shared Ucapan Terimakasih Charles Hono...          1\n","3     Wah pak Jokowi sudah mendapat nilai positif di...          1\n","4     Penelpon : raffi ahmad oh raffi ahmad..... *bu...          1\n","...                                                 ...        ...\n","5043  linen nya terasa agak gatal... mungkin kurang ...          0\n","5044  Didaskaleinophobia adalah takut akan pergi ke ...          0\n","5045  Iklan partai Demokrat Katakan Tidak Pada Korup...          0\n","5046        Tempat tidurnya nyaman toilet kurang bersih          0\n","5047  Cari Anggota Baru, Geng Motor Sebar Formulir k...          0\n","\n","[5048 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["indolem_path0 = pd.read_csv('./data/indonesian-sentiment-dataset/indolem/data/test0.csv')\n","indolem_path1 = pd.read_csv('./data/indonesian-sentiment-dataset/indolem/data/test1.csv')\n","indolem_path2 = pd.read_csv('./data/indonesian-sentiment-dataset/indolem/data/test2.csv')\n","indolem_path3 = pd.read_csv('./data/indonesian-sentiment-dataset/indolem/data/test3.csv')\n","indolem_path4 = pd.read_csv('./data/indonesian-sentiment-dataset/indolem/data/test4.csv')\n","dfs = [indolem_path0, indolem_path1, indolem_path2, indolem_path3, indolem_path4]\n","df_test = pd.concat(dfs, ignore_index=True)\n","df_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1646721664219,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"o5h2mAvj2iQM","outputId":"c738b373-57de-4c94-b0b2-d69c024faad0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total positive review:  1486\n","Total negative review:  3562\n"]}],"source":["print('Total positive review: ', df_test.loc[df_test['sentiment'] == 1].shape[0])\n","print('Total negative review: ', df_test.loc[df_test['sentiment'] == 0].shape[0])"]},{"cell_type":"markdown","metadata":{"id":"plTpL8n9NNvS"},"source":["## Load a model which was fine-tuned using English and Japanese review datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22815,"status":"ok","timestamp":1646721687030,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"1hvL7Res3uRV","outputId":"cc646053-ea7f-4701-b4b8-93a5da869e58"},"outputs":[{"data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","model_dir = \"./models/enja-binary-model/model_save/\"\n","# Load a model fine-tuned using English and Japanese review data\n","model = XLMRobertaForSequenceClassification.from_pretrained(model_dir)\n","tokenizer = XLMRobertaTokenizer.from_pretrained(model_dir)\n","# Copy the model to the GPU.\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"bQUawXgvNZCP"},"source":["## Preparing for Sentiment Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MGyJYxh33lt"},"outputs":[],"source":["from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score\n","import itertools\n","\n","MAX_LEN = 64\n","\n","def predict_new (treviews, tsentiments):\n","  # Tokenize all of the sentences and map the tokens to their word IDs.\n","  input_ids = []\n","  # For every sentence...\n","  for sent in treviews:\n","      # `encode` will:\n","      #   (1) Tokenize the sentence.\n","      #   (2) Prepend the `[CLS]` token to the start.\n","      #   (3) Append the `[SEP]` token to the end.\n","      #   (4) Map tokens to their IDs.\n","      encoded_sent = tokenizer.encode(\n","                          sent,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          truncation=True,\n","                          max_length=128\n","                    )\n","      \n","      input_ids.append(encoded_sent)\n","  # Pad our input tokens\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                            dtype=\"long\", truncating=\"post\", padding=\"post\")\n","  # Create attention masks\n","  attention_masks = []\n","  # Create a mask of 1s for each token followed by 0s for padding\n","  for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask) \n","  # Convert to tensors.\n","  prediction_inputs = torch.tensor(input_ids)\n","  prediction_masks = torch.tensor(attention_masks)\n","  prediction_labels = torch.tensor(tsentiments)\n","  # Set the batch size.  \n","  batch_size = 32  \n","  # Create the DataLoader.\n","  prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","  prediction_sampler = SequentialSampler(prediction_data)\n","  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","  # Prediction on test set\n","  print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","  # Put model in evaluation mode\n","  model.eval()\n","  # Tracking variables \n","  predictions , true_labels = [], []\n","  # Predict \n","  for batch in prediction_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # Telling the model not to compute or store gradients, saving memory and \n","    # speeding up prediction\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","  print('DONE.')\n","  accs = []\n","  maes = []\n","  # For each input batch...\n","  for i in range(len(true_labels)):\n","    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","    # and one column for \"1\"). Pick the label with the highest value and turn this\n","    # in to a list of 0s and 1s.\n","    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","    print(pred_labels_i)\n","    acc = accuracy_score(true_labels[i], pred_labels_i)\n","    mae = mean_absolute_error(true_labels[i], pred_labels_i)\n","    accs.append(acc)\n","    maes.append(mae)\n","\n","  # print(\"Trained with {} data\".format(len(df_train)))\n","  print(\"Accuracy on the Test Set ({} data): \".format(len(treviews)), sum(accs)/len(accs)*100)\n","  print(\"MAE on the Test Set ({} data): \".format(len(treviews)), sum(maes)/len(maes)*100)\n","\n","  # print F1-score\n","  preds = []\n","  for i in range(len(predictions)):\n","    preds.append(np.argmax(predictions[i], axis=1).flatten())\n","  truth = list(itertools.chain.from_iterable(true_labels))\n","  preds = list(itertools.chain.from_iterable(preds))\n","  f1s = f1_score(truth, preds, average='macro') # macro averaged f1 score\n","  print(\"F1 Score on the Test Set ({} data): \".format(len(treviews)), f1s*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zppeHDAI3-Vr"},"outputs":[],"source":["newreviews = df_test['sentence'].values\n","newsentiments = df_test['sentiment'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iz_nPAev4Fmj"},"outputs":[],"source":["newreviews[2000:2100]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1646722995074,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"bHu1Lyad4Ie8","outputId":"f002a2b7-d39e-478e-ae79-09a2966a879e"},"outputs":[{"data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["newsentiments[2000:2100]"]},{"cell_type":"markdown","metadata":{"id":"Fv4PYeY_Nmcb"},"source":["## Start Predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1646723105230,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11890750785389102535"},"user_tz":-540},"id":"3gmQcMqx4JRL","outputId":"9f93e603-d2d5-49ec-c779-21cca427d00e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicting labels for 2 test sentences...\n","DONE.\n","[1 0]\n","Accuracy on the Test Set (2 data):  50.0\n","MAE on the Test Set (2 data):  50.0\n","F1 Score on the Test Set (2 data):  33.33333333333333\n"]}],"source":["predict_new(newreviews, newsentiments)"]},{"cell_type":"markdown","metadata":{"id":"O_5oB_Ug_bLK"},"source":["# Start Predicting (Binary)\n","> IndoNLU (SmSA) Sentiment Dataset"]},{"cell_type":"markdown","metadata":{"id":"CnakjHDBN6jW"},"source":["## Load the Indonesian sentiment data (SmSA) also used by IndoNLU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":896,"status":"ok","timestamp":1617864188340,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"","userId":"11890750785389102535"},"user_tz":-540},"id":"KH1_XB_H_bLV","outputId":"5f79b0ed-91f2-40c9-aac0-ebe96995b500"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total review:  1260\n","Total neutral review:  131\n","Total positive review:  735\n","Total negative review:  394\n","Total number of testing data:  1129\n","Total positive review:  735\n","Total negative review:  394\n"]}],"source":["df_test = pd.read_csv('./data/indonesian-sentiment-dataset/indonlu/valid_preprocess.tsv', delimiter='\\t', header=None)\n","\n","print('Total review: ', df_test.shape[0])\n","print('Total neutral review: ', df_test.loc[df_test[1] == 'neutral'].shape[0])\n","print('Total positive review: ', df_test.loc[df_test[1] == 'positive'].shape[0])\n","print('Total negative review: ', df_test.loc[df_test[1] == 'negative'].shape[0])\n","\n","#Remove all NEUTRAL reviews\n","df_test = df_test[df_test[1] != 'neutral']\n","print('Total number of testing data: ',df_test.shape[0])\n","\n","def label_sentiment (row):\n","    if row[1] == 'negative':\n","      return 0\n","    elif row[1] == 'positive':\n","      return 1\n","\n","df_test['sentiment'] = df_test.apply(lambda row: label_sentiment(row), axis=1)\n","print('Total positive review: ', df_test.loc[df_test['sentiment'] == 1].shape[0])\n","print('Total negative review: ', df_test.loc[df_test['sentiment'] == 0].shape[0])"]},{"cell_type":"markdown","metadata":{"id":"RCGPQIdiOUco"},"source":["## Load a model which was fine-tuned using English and Japanese review datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30186,"status":"ok","timestamp":1617864226636,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"","userId":"11890750785389102535"},"user_tz":-540},"id":"knCHZT0O_bLV","outputId":"4ef613d0-fae2-4fac-99de-5e3e118759d8"},"outputs":[{"data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"execution_count":15,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["#...\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","model_dir = \"./models/en-binary-model/model_save/\"\n","# Load a trained model and vocabulary that you have fine-tuned\n","model = XLMRobertaForSequenceClassification.from_pretrained(model_dir)\n","tokenizer = XLMRobertaTokenizer.from_pretrained(model_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"oC4NcSGvOZEe"},"source":["## Preparing for Sentiment Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BJsmb6h_bLV"},"outputs":[],"source":["from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score\n","import itertools\n","\n","MAX_LEN = 64\n","\n","def predict_new (treviews, tsentiments):\n","  # Tokenize all of the sentences and map the tokens to thier word IDs.\n","  input_ids = []\n","  # For every sentence...\n","  for sent in treviews:\n","      # `encode` will:\n","      #   (1) Tokenize the sentence.\n","      #   (2) Prepend the `[CLS]` token to the start.\n","      #   (3) Append the `[SEP]` token to the end.\n","      #   (4) Map tokens to their IDs.\n","      encoded_sent = tokenizer.encode(\n","                          sent,                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          truncation=True,\n","                          max_length=128\n","                    )\n","      \n","      input_ids.append(encoded_sent)\n","  # Pad our input tokens\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                            dtype=\"long\", truncating=\"post\", padding=\"post\")\n","  # Create attention masks\n","  attention_masks = []\n","  # Create a mask of 1s for each token followed by 0s for padding\n","  for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask) \n","  # Convert to tensors.\n","  prediction_inputs = torch.tensor(input_ids)\n","  prediction_masks = torch.tensor(attention_masks)\n","  prediction_labels = torch.tensor(tsentiments)\n","  # Set the batch size.  \n","  batch_size = 32  \n","  # Create the DataLoader.\n","  prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","  prediction_sampler = SequentialSampler(prediction_data)\n","  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","  # Prediction on test set\n","  print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","  # Put model in evaluation mode\n","  model.eval()\n","  # Tracking variables \n","  predictions , true_labels = [], []\n","  # Predict \n","  for batch in prediction_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # Telling the model not to compute or store gradients, saving memory and \n","    # speeding up prediction\n","    with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","  print('DONE.')\n","  accs = []\n","  maes = []\n","  # For each input batch...\n","  for i in range(len(true_labels)):\n","    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","    # and one column for \"1\"). Pick the label with the highest value and turn this\n","    # in to a list of 0s and 1s.\n","    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","    acc = accuracy_score(true_labels[i], pred_labels_i)\n","    mae = mean_absolute_error(true_labels[i], pred_labels_i)\n","    accs.append(acc)\n","    maes.append(mae)\n","\n","  # print(\"Trained with {} data\".format(len(df_train)))\n","  print(\"Accuracy on the Test Set ({} data): \".format(len(treviews)), sum(accs)/len(accs)*100)\n","  print(\"MAE on the Test Set ({} data): \".format(len(treviews)), sum(maes)/len(maes)*100)\n","\n","  # print F1-score\n","  preds = []\n","  for i in range(len(predictions)):\n","    preds.append(np.argmax(predictions[i], axis=1).flatten())\n","  truth = list(itertools.chain.from_iterable(true_labels))\n","  preds = list(itertools.chain.from_iterable(preds))\n","  f1s = f1_score(truth, preds, average='macro') # macro averaged f1 score\n","  print(\"F1 Score on the Test Set ({} data): \".format(len(treviews)), f1s*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_9RLsqv_bLW"},"outputs":[],"source":["newreviews = df_test[0].values\n","newsentiments = df_test['sentiment'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1164,"status":"ok","timestamp":1617864277415,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"","userId":"11890750785389102535"},"user_tz":-540},"id":"Gxo8ieQZ_bLW","outputId":"ad83ca1a-9ab6-46ea-f254-279316f0e15d"},"outputs":[{"data":{"text/plain":["array(['tidak enak',\n","       'restoran ini menawarkan makanan sunda . kami memesan ayam goreng , kangkung , sayur asam , ikan gurame goreng , ikan bakar , nasi goreng , karedok , tahu tempe , nasi putih , nasi merah etc minuman yang mereka tawarkan juga cukup variatif . rasa makanan enak dan harga murah . kami 9 dewasa dan 5 anak kecil , hanya menghabiskan 800,000',\n","       'lokasi di alun alun masakan padang ini cukup terkenal dengan kepala ikan kakap gule , biasa saya pesan nasi bungkus padang berisikan rendang , ayam pop dan perkedel . porsi banyak dan mengenyangkan',\n","       ...,\n","       'be de gea , cowok cupu yang takut dengan pacar nya . pacar nya mau tinggal di madrid eh nurut aja . payah',\n","       'valen yang sangat tidak berkualitas . konentator harus nya mendidik . bukan yang jebret jebret , awas , kuat , rata , pait pait .',\n","       'restoran ini menjadi tempat pilihan saya berbuka puasa minggu lalu . pelayanan yang diberikan baik dengan pilhan menu yang banyak . yang saya suka adalah rasa ayam goreng nya yang khas .'],\n","      dtype=object)"]},"execution_count":18,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["newreviews"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":797,"status":"ok","timestamp":1617864277416,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"","userId":"11890750785389102535"},"user_tz":-540},"id":"wUaDUV8Z_bLX","outputId":"a9384441-6288-4758-e8f5-0f41502b2d38"},"outputs":[{"data":{"text/plain":["array([0, 1, 1, ..., 0, 0, 1])"]},"execution_count":19,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["newsentiments"]},{"cell_type":"markdown","metadata":{"id":"ZOSqn8QGOcN_"},"source":["## Start Predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5458,"status":"ok","timestamp":1617864291574,"user":{"displayName":"ANDRE RUSLI (10110110103)","photoUrl":"","userId":"11890750785389102535"},"user_tz":-540},"id":"78FGiJY0_bLX","outputId":"d0313cb7-5ed1-4d02-dfb0-fc55282f09d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicting labels for 1,129 test sentences...\n","DONE.\n","Accuracy on the Test Set (1129 data):  87.83757716049382\n","MAE on the Test Set (1129 data):  12.162422839506174\n","F1 Score on the Test Set (1129 data):  86.77115040607009\n"]}],"source":["predict_new(newreviews, newsentiments)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRdD-bHc_bLX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM6FSpYsdOc5zHwfQJvzMtc","collapsed_sections":["O_5oB_Ug_bLK"],"name":"id-sentiment-classification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
